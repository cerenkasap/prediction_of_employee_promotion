## Prediction of Employee Promotion - Binary Classification üèÜ: Project Overview

Applied **Logistic Regression, Support Vector Classifier, Random Forest Classifier, Bernoulli Naive Bayes**, and **KNeighborsClassifier** and optimized using **GridSearchCV** to find the best model.

### Code Used

Python version: *Python 3.7.11* 

### Resources Used

[Calculating the missing value ratio](https://www.analyticsvidhya.com/blog/2021/04/beginners-guide-to-missing-value-ratio-and-its-implementation/)

[Binary classification project with similar dataset](https://www.kaggle.com/code/avi111297/eda-on-employee-promo-pred-got-93-6-accuracy)

[Binary classification project with similar dataset](https://www.kaggle.com/code/amulya9/predict-employee-promotion-result/notebook)


## Data Collection

## Data Cleaning

## Exploratory Data Analysis

## Model Building


Data were split into **train (80%)** and **test (20%)** sets.

I used six models *(Decision Tree Classifier, Logistic Regression, Support Vector Classifier, Random Forest Classifier, Bernoulli Bayes, and KNeighborsClassifier)* to predict the sentiment and evaluated them by using *Accuracy*.

## Model Performance Evalution
Logistic Regression model performed better than any other models in this project.

|Model                      |Test Accuracy Score|                      
| -------------             |:-----------------:|                       
|Decision Tree              |0.9195253234957474|
|Logistic Regression        |0.7659303362220304|
|Support Vector Classifier  |0.8381531307413898|
|Random Forest Classifier   |0.9524331256811436|
|Naive Bayes                |0.6817535632799406|
|K-Neighbots                |0.8508799620065138|

## Hyperparameter Tuning


## Best Model


## Confusion Matrix


Thanks for reading :) 
